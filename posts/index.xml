<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Hello World</title><link>https://shellming.github.io/posts/</link><description>Recent content in Posts on Hello World</description><generator>Hugo -- gohugo.io</generator><language>zh-cn</language><lastBuildDate>Tue, 18 Dec 2018 00:00:00 +0000</lastBuildDate><atom:link href="https://shellming.github.io/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>UFW 防火墙常用设置</title><link>https://shellming.github.io/2018/12/18/ufw/</link><pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate><guid>https://shellming.github.io/2018/12/18/ufw/</guid><description>安装与卸载 直接执行命令 ufw 查看 ufw 是否安装，如果没有安装执行 sudo apt-get install ufw 安装 ufw，如果需要卸载使用 sudo apt-get install ufw 命令。
启用 IPv6 如果服务器启用了 IPv6，需要开启 ufw 的 IPv6 支持。编辑文件 /etc/default/ufw，确保 IPv6 的值为 yes。 &amp;gt; &amp;hellip; &amp;gt; IPV6=yes &amp;gt; &amp;hellip;
设置默认策略 一般默认策略为允许所有传出请求，拒绝所有传入请求，配置如下：
sudo ufw default deny incoming sudo ufw default allow outgoing 具体规则配置 按服务名配置 sudo ufw allow ssh # 允许 ssh 连接 sudo ufw allow ssh/tcp # 增加了协议 按端口配置 sudo ufw deny 22 sudo ufw deny 22/tcp 拒绝某个 IP 段对某个端口的访问 如果本机地址为 192.</description></item><item><title>Guava Retrying</title><link>https://shellming.github.io/2018/12/13/guava-retrying/</link><pubDate>Thu, 13 Dec 2018 00:00:00 +0000</pubDate><guid>https://shellming.github.io/2018/12/13/guava-retrying/</guid><description>简介 Guava Retrying 是一个灵活的 Java 重试工具，该工具基于Guava 的 predicate 机制， 提供了处理各种停止、重试、异常处理的能力。相较于 Spring Retry 只能根据抛出的异常决定是否重试，Guava Retrying 可以根据返回结果来决定是否重试，功能更加强大。项目 Github 地址
基本使用 官网的基本用例
Callable&amp;lt;Boolean&amp;gt; callable = new Callable&amp;lt;Boolean&amp;gt;() { public Boolean call() throws Exception { return true; // do something useful here } }; Retryer&amp;lt;Boolean&amp;gt; retryer = RetryerBuilder.&amp;lt;Boolean&amp;gt;newBuilder() .retryIfResult(Predicates.&amp;lt;Boolean&amp;gt;isNull()) .retryIfExceptionOfType(IOException.class) .retryIfRuntimeException() .withStopStrategy(StopStrategies.stopAfterAttempt(3)) .build(); try { retryer.call(callable); } catch (RetryException e) { e.printStackTrace(); } catch (ExecutionException e) { e.printStackTrace(); } 重试条件：结果返回 null 或者抛出 IOException 或者抛出 RuntimeException 停止条件：尝试三次，失败后停止 RetryException：尝试失败后抛出，包含了失败信息 ExecutionException：执行过程中抛出了预料之外的异常，终止了执行 Fibonacci Backoff 一直重试，永不停止，每次重试失败后的间隔时间为一个斐波那契数列，最大间隔时间为2分钟</description></item><item><title>RSA 公钥私钥生成及使用</title><link>https://shellming.github.io/2018/12/11/rsa/</link><pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate><guid>https://shellming.github.io/2018/12/11/rsa/</guid><description>有些接口交互需要用 RSA 算法对参数进行签名以保证安全性，记录一下 RSA 密钥对的生成以及使用
秘钥生成 为方便 Java 使用，最终生成的私钥需要转化成 PKCS8 格式
# 生成 SSLeay 格式的 rsa 私钥 openssl genrsa -out rsaprivatekey.pem 1024 # 生成对应的公钥 openssl rsa -in rsaprivatekey.pem -pubout -out rsapublickey.pem # 将 RSA 私钥转换成 PKCS8 格式 openssl pkcs8 -topk8 -inform PEM -in rsaprivatekey.pem -outform PEM -nocrypt -out rsaprivatepkcs8.pem 由于生成的私钥中已经包含了公钥信息，所以服务器端只要保存私钥就可以了，需要的时候可以从私钥中导出公钥
# 将私钥从 PKCS8 格式转回 SSLeay 格式的 openssl rsa -in rsaprivatepkcs8.pem -out ssleay.pem # 提取公钥 openssl rsa -in ssleay.pem -pubout -out rsapublickey.</description></item><item><title>Spark 常用参数设置</title><link>https://shellming.github.io/2018/12/11/spark-param/</link><pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate><guid>https://shellming.github.io/2018/12/11/spark-param/</guid><description>记录一些常用的必须要设置的参数
num-executors 说明：该参数用于设置Spark作业总共要用多少个Executor进程来执行 建议：设置的太少，无法充分利用集群资源；设置的太多的话，大部分队列可能无法给予充分的资源。建议 50~100个 .executor-cores 说明：用于设置每个Executor进程的CPU core数量。 建议：如果设置过少（例如设为1），无法发挥单个 work 进程的并发能力，如果设置过大，如果有 HDFS 的 IO 操作，会使单个节点网络压力较大。建议设为 2~4 .executor-memory 说明：该参数用于设置每个Executor进程的内存。 建议：每个Executor进程的内存设置4G~8G较为合适。 .driver-memory 说明：该参数用于设置Driver进程的内存。 建议：如果有大的 collect 操作的话，需要设大一点，保证 Driver 内存能装得下 .spark.default.parallelism 说明：该参数用于设置每个stage的默认task数量。 建议：设置该参数为num-executors * executor-cores的2~3倍较为合适 .yarn.executor.directMemoryOverhead / .yarn.driver.directMemoryOverhead 说明：控制 Driver 和 Executor 的 Direct memory ，如果执行过程中出现 direct memory oom 异常，可以将这两个值适当调大一些 建议：默认为 256m ，建议 512m 补充说明 Direct memory 也叫做 off heap memory， 是在 jvm heap 之外的由操作系统直接管理的本地内存。 也就是说，这部分内存并不会被 jvm 的拉圾回收器管理。 jvm 本身有参数 MaxDirectMemorySize 控制 jvm 进程能用的最大的 offheap 内存，超出这个内存就会报出 Direct memory oom 。由于 Spark 本质上也是分布式的 jvm 程序，所以 direct memory 的最大使用量也最终由这个参数控制。 在Spark中，direct memory分为三部分： - jvmOverhead jvmOverhead 是 jvm 自身一些lib库，以及线程栈, 内部数据结构占用的堆外内存 - directMemoryOverhead directMemoryOverhead 是 spark 框架本身进行一些网络 io 操作/文件 io 操作/ execution(shuffle,join等)/storage(cache 数据)使用的堆外内存 - otherOverhead otherOverhead 是其他的一些框架占用的direct内存，比如 HBase，或者用户代码中使用的堆外内存，默认大小为0，一般可以忽略。</description></item></channel></rss>